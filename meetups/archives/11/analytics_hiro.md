# <analytics_hiro>

## 会社や業務で普段やっていること

BIや機械学習のモデル作成などやってます。
(pythonなどは書きますが非エンジニアです)

## 今日取り組むこと

digdagワークフローを触って仕様を理解する。
GCPのプロジェクトでbq→gcsなどのスケジュールを組んでみる

## (option) 相談するかもしれないこと

今日はローカルですが、最近、業務ではGCPのVMに環境構築してモデル作成などやっているので、そこらへん詳しい人がいたらいろいろ聞きたいです。。。（GCP初心者なので）

## (option) 得意とすること・教えられること

データ分析、統計、機械学習まわりなど多少は

## やったこと

- digdag仕様把握（ドキュメント読む）
- digdagのインストール・設定
- 使いそうな各operator実装・実行
	- linuxコマンドの実行
	- pythonの実行
	- GCPへのアクセス
	- BQへのクエリ実行
	- GCSへのデータ格納
	- httpリクエストでのerror発生時のslackへの通知
	- digdagワークフローのスケジューリング

## 結果

- インストール簡単
- Dockerや分散処理などにも対応（らしい）
- フォーマットがyamlかつoperatorが用意されているのでBQ,GCS,RS,S3,TDなど各データベースに対するワークフロー実装が非常に簡単で、学習コストが低い（operatorがない場合でも、3rd partyからプラグインが用意されていたりする）
- ifやwaitなんかも記述できて、ある程度柔軟性もありそう
- スケジューリングも内包していて、各DWH、RDSなどに用意されているGUIベースのジョブ管理使うよりも、まとめてコード管理できるので良さそう(cronよりも楽だと思った)
- BQのプロジェクト跨いだクエリ発行をそれぞれのサービスアカウント使ってどうやるか、わからなかった（そもそもできない？）
